<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Training dynamics of A Single ReLU Neuron | Ziming Liu </title> <meta name="author" content="Ziming Liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kindxiaoming.github.io/blog/2026/single-relu-neuron/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>window.MathJax={tex:{tags:"ams"}};</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziming</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">media coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/talk/">talk </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Training dynamics of A Single ReLU Neuron</h1> <p class="post-meta"> Created in January 03, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/physics-of-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Physics-of-AI</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Author: Ziming Liu (刘子鸣)</strong></p> <hr> <h2 id="motivation">Motivation</h2> <p>In a previous <a href="/blog/2026/feature-learning-1/">blog post</a>, we studied feature learning in shallow, wide MLPs. In this article, we consider an even simpler setting: an MLP with only <strong>one hidden layer</strong>, <strong>a single ReLU neuron</strong>, and a <strong>self-generated target function</strong> (a teacher network).</p> <p>In this setting, we know that there exists a set of weights for which the loss is exactly zero. But will gradient-based optimization run into difficulties? For example, if the neuron is initialized to be overly <strong>active</strong> (positive pre-activation for all inputs), or overly <strong>inactive</strong> (negative pre-activation for all inputs), will optimization fail? Even if the initialization is reasonable, can the training dynamics drive the neuron into a bad state (too active or too inactive)?</p> <p>For convenience, we define three states of a neuron:</p> <ul> <li> <strong>Hyperactive</strong>: activated for all inputs (pre-activation always positive)</li> <li> <strong>Inactive / Dead</strong>: never activated (pre-activation always negative)</li> <li> <strong>Balanced</strong>: activated for some inputs and inactive for others</li> </ul> <p>Although this setup is extremely simple, our ultimate goal is to gain insights relevant to LLM training. One intuition is that many tricks used in LLM training—such as LR warmup, LR decay, weight decay, and MoE balancing—may implicitly control neuron activity levels, thereby influencing feature learning.</p> <hr> <h2 id="problem-setup">Problem Setup</h2> <p>An MLP with one hidden layer and one neuron can be written as (for simplicity, the input is also 1D):</p> \[f(x; w_1, b_1, w_2, b_2) = w_2\sigma(w_1x+b_1)+b_2, \quad \sigma(x) ={\rm ReLU}(x) \equiv {\rm max}(0,x)\] <p>For the teacher network, we set \(w_1^T = w_2^T = 1, \quad b_1^T = b_2^T = 0\), and so \(f(x)\equiv {\rm ReLU}(x)\). We take the input domain to be \(x \in [-1,1].\)</p> <p>For the student network, we initialize \(w_1^S = w_2^S = 1,\) and focus on varying the initializations of \(b_1^S\) and \(b_2^S\). Training uses MSE loss and the Adam optimizer (default LR = 0.01). Below, we only discuss the student’s weights, so we omit the superscript \(S\).</p> <hr> <h2 id="observation-0-large-b_1-leads-to-local-minima">Observation 0: Large \(|b_1|\) Leads to Local Minima</h2> <p>We fix the initialization \(b_2 = 0\).</p> <ul> <li>When \(b_1 &gt; 1\), the neuron is initialized in the <strong>hyperactive</strong> state, and the loss gets stuck around 0.02 (corresponding to approximating ReLU with linear regression).</li> <li>When \(b_1 &lt; -1\), the neuron is initialized in the <strong>dead</strong> state, and the loss gets stuck around 0.1 (corresponding to approximating ReLU with a constant function).</li> </ul> <p>This may help explain why some initialization schemes (e.g., Kaiming initialization) set the bias to zero.</p> <hr> <h2 id="observation-1-large-b_2-can-kill-the-neuron">Observation 1: Large \(|b_2|\) Can Kill the Neuron</h2> <p>We fix \(b_1 = 0\), so the neuron is <strong>balanced</strong> at initialization. Is everything fine then? Not quite. We find that when \(b_2 = -1.1\), the loss can go to zero, but when \(b_2 = -1.2\), the loss gets stuck around 0.02 (again corresponding to approximating ReLU with linear regression).</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 90%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/single-relu-neuron/loss-480.webp 480w,/assets/img/blogs/single-relu-neuron/loss-800.webp 800w,/assets/img/blogs/single-relu-neuron/loss-1400.webp 1400w,/assets/img/blogs/single-relu-neuron/loss-1920.webp 1920w,/assets/img/blogs/single-relu-neuron/loss-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/single-relu-neuron/loss.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>By closely examining the training dynamics, we find that the turning point \(x_t \equiv - b_1 / w_1\) moves left during training (starting from 0). When it moves past -1, the neuron transitions from <strong>balanced</strong> to <strong>hyperactive</strong>.</p> <p>The local minimum for \(b_2 = -1.2\) corresponds to the linear regression solution (the neuron is in the hyperactive state):</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 90%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/single-relu-neuron/large_b2_init-480.webp 480w,/assets/img/blogs/single-relu-neuron/large_b2_init-800.webp 800w,/assets/img/blogs/single-relu-neuron/large_b2_init-1400.webp 1400w,/assets/img/blogs/single-relu-neuron/large_b2_init-1920.webp 1920w,/assets/img/blogs/single-relu-neuron/large_b2_init-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/single-relu-neuron/large_b2_init.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Conversely, if we increase the bias of the target function, the neuron also transitions from <strong>balanced</strong> to <strong>hyperactive</strong>.</p> <p>This observation connects to two empirical practices:</p> <ul> <li> <strong>Model bias</strong>: In some LLM training setups, bias terms are disabled. The observation above suggests that bias dynamics can drive neurons away from the balanced state.</li> <li> <strong>Data bias</strong>: Whitening inputs and normalizing intermediate representations are common practices.</li> </ul> <hr> <h2 id="observation-2-too-large-a-learning-rate-can-also-kill-the-neuron">Observation 2: Too Large a Learning Rate Can Also Kill the Neuron</h2> <p>We fix \(b_1 = 0\) and \(b_2 = -1\).</p> <ul> <li>When LR = 0.2, the model’s loss can be optimized to zero.</li> <li>When LR = 0.4, the loss only reaches 0.1 (again corresponding to fitting ReLU with a constant function), because the neuron becomes <strong>dead</strong>.</li> </ul> <p>This may be related to LR warmup in LLM training: if the initial learning rate is too large, the loss may decrease quickly, but at the cost of killing some neurons. Once dead, these neurons are hard (or impossible) to bring back to a balanced state.</p> <hr> <h2 id="observation-3-silu-eventually-recovers-but-gets-stuck-at-a-saddle-point-for-a-long-time">Observation 3: SiLU Eventually Recovers, but Gets Stuck at a Saddle Point for a Long Time</h2> <p>For SiLU, we observe that the loss can eventually reach zero (up to machine precision), but training gets stuck at saddle points for very long time, reducing training efficiency.</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 90%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/single-relu-neuron/silu-480.webp 480w,/assets/img/blogs/single-relu-neuron/silu-800.webp 800w,/assets/img/blogs/single-relu-neuron/silu-1400.webp 1400w,/assets/img/blogs/single-relu-neuron/silu-1920.webp 1920w,/assets/img/blogs/single-relu-neuron/silu-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/single-relu-neuron/silu.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h2 id="takeaway">Takeaway</h2> <p><strong>Irreversibility</strong>: once a neuron leaves the balanced state, it is very hard to return. Bias plays a crucial role. This might be why we have various ugly tricks for LLM (learning rate schedule, weight decay, etc).</p> <hr> <h2 id="questionsideas">Questions/Ideas</h2> <p><strong>Question 1: How can we better control bias?</strong></p> <ul> <li>Can we analytically compute the bias instead of learning it via gradient descent?</li> <li>Can we use a different parameterization to better control neuron activation? For example, \(wx + b \;\to\; w(x + b'),\) where \(b'\) directly controls neuron activation (assuming the input distribution is known). This may allow us to more directly control neuron activity, e.g., by applying weight decay to \(b'\) or explicitly enforcing balancing.</li> </ul> <p><strong>Question 2: Which neurons have better learning dynamics?</strong></p> <ul> <li>SiLU is better than ReLU. Is there something better, gating?</li> </ul> <hr> <h2 id="code">Code</h2> <p>Google Colab notebook available <a href="https://colab.research.google.com/drive/1gSrKOVfEtVNTa7ZCUOpqOI1uTXm0SL9s?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>.</p> <hr> <h2 id="citation">Citation</h2> <p>If you find this article useful, please cite it as:</p> <p><strong>BibTeX:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2026single-relu-neuron</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Training dynamics of A Single ReLU Neuron}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liu, Ziming}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{January}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{https://KindXiaoming.github.io/blog/2026/single-relu-neuron/}</span>
<span class="p">}</span>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/unigram-toy-1/">Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/physics-ml-theory/">A Good ML Theory is Like Physics -- A Physicist's Analysis of Grokking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/feature-learning-1/">Physics of Feature Learning 1 – A Perspective from Nonlinearity</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/induction-head-lr-schedule/">Emergence of Induction Head Depends on Learning Rate Schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/fine-tuning-sparsity/">Fine-tuning with sparse updates? A toy teacher-student Setup</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ziming Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" crossorigin="anonymous"></script> <script>window.addEventListener("load",function(){console.log("Page loaded. MathJax available:",void 0!==window.MathJax),void 0!==window.MathJax?console.log("MathJax version:",window.MathJax.version):console.error("MathJax failed to load!")});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-media-coverage",title:"media coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/media/"}},{id:"nav-talk",title:"talk",description:"",section:"Navigation",handler:()=>{window.location.href="/talk/"}},{id:"post-depth-3-fun-facts-about-loss-hessian-eigenvalues",title:"Depth 3 -- Fun facts about loss hessian eigenvalues",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-3/"}},{id:"post-diffusion-2-visualizing-flow-matching-temporal-dynamics",title:"Diffusion 2 -- Visualizing flow matching, temporal dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-2/"}},{id:"post-sparse-attention-7-stack-of-causal-attention-creates-implicit-positional-embedding-and-explaning-quot-loss-in-the-middle-quot",title:"Sparse attention 7 -- Stack of causal attention creates implicit positional embedding, and explaning &quot;Loss in the middle&quot;",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-7/"}},{id:"post-sparse-attention-6-in-context-associative-recall",title:"Sparse attention 6 -- In-context Associative recall",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-6/"}},{id:"post-mlp-2-effective-linearity-generalized-silu",title:"MLP 2 -- Effective linearity, Generalized SiLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-2/"}},{id:"post-mlp-1-gating-is-good-for-polynomials",title:"MLP 1 -- Gating is good for polynomials",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-1/"}},{id:"post-optimization-4-loss-spikes",title:"Optimization 4 -- Loss Spikes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-4/"}},{id:"post-optimization-3-depth-2-adding-bias-after-relu",title:"Optimization 3 / Depth 2 -- Adding Bias After ReLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-3/"}},{id:"post-optimization-2-elementwise-scale-reparametrization",title:"Optimization 2 -- Elementwise Scale Reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-2/"}},{id:"post-optimization-1-norm-reparametrization",title:"Optimization 1 -- Norm reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-1/"}},{id:"post-sparse-attention-5-attention-sink",title:"Sparse attention 5 -- Attention sink",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-5/"}},{id:"post-bigram-4-on-the-difficulty-of-spatial-map-emergence",title:"Bigram 4 -- On the difficulty of spatial map emergence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-4/"}},{id:"post-depth-1-understanding-pre-ln-and-post-ln",title:"Depth 1 -- Understanding Pre-LN and Post-LN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-1/"}},{id:"post-bigram-3-low-rank-structure",title:"Bigram 3 -- Low Rank Structure",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-3/"}},{id:"post-bigram-2-emergence-of-hyperbolic-spaces",title:"Bigram 2 -- Emergence of Hyperbolic Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-2/"}},{id:"post-bigram-1-walk-on-a-circle",title:"Bigram 1 -- Walk on a Circle",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-1/"}},{id:"post-diffusion-1-sparse-and-dense-neurons",title:"Diffusion 1 -- Sparse and Dense Neurons",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-1/"}},{id:"post-sparse-attention-4-previous-token-head",title:"Sparse attention 4 -- previous token head",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-4/"}},{id:"post-sparse-attention-3-inefficiency-of-extracting-similar-content",title:"Sparse attention 3 -- inefficiency of extracting similar content",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-3/"}},{id:"post-emergence-of-induction-head-depends-on-learning-rate-schedule",title:"Emergence of Induction Head Depends on Learning Rate Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/induction-head-lr-schedule/"}},{id:"post-sparse-attention-2-unattention-head-branching-dynamics",title:"Sparse attention 2 -- Unattention head, branching dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-2/"}},{id:"post-sparse-attention-1-sticky-plateau-and-rank-collapse",title:"Sparse attention 1 -- sticky plateau and rank collapse",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-1/"}},{id:"post-unigram-toy-model-is-surprisingly-rich-representation-collapse-scaling-laws-learning-rate-schedule",title:"Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/unigram-toy-1/"}},{id:"post-fine-tuning-with-sparse-updates-a-toy-teacher-student-setup",title:"Fine-tuning with sparse updates? A toy teacher-student Setup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/fine-tuning-sparsity/"}},{id:"post-multi-head-cross-entropy-loss",title:"Multi-Head Cross Entropy Loss",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/multi-head-cross-entropy/"}},{id:"post-what-39-s-the-difference-physics-of-ai-physics-math-and-interpretability",title:"What&#39;s the difference -- (physics of) AI, physics, math and interpretability",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/ai-physics-interpretability/"}},{id:"post-representation-anisotropy-from-nonlinear-functions",title:"Representation anisotropy from nonlinear functions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/activation-anisotropy/"}},{id:"post-training-dynamics-of-a-single-relu-neuron",title:"Training dynamics of A Single ReLU Neuron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/single-relu-neuron/"}},{id:"post-physics-of-ai-how-to-begin",title:"Physics of AI \u2013 How to Begin",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-of-ai-recipe/"}},{id:"post-physics-of-feature-learning-1-a-perspective-from-nonlinearity",title:"Physics of Feature Learning 1 \u2013 A Perspective from Nonlinearity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/feature-learning-1/"}},{id:"post-physics-of-ai-requires-mindset-shifts",title:"Physics of AI Requires Mindset Shifts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/physics-of-ai/"}},{id:"post-achieving-agi-intelligently-structure-not-scale",title:"Achieving AGI Intelligently \u2013 Structure, Not Scale",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/structuralism-ai/"}},{id:"post-philosophical-thoughts-on-kolmogorov-arnold-networks",title:"Philosophical thoughts on Kolmogorov-Arnold Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kolmogorov-arnold-networks/"}},{id:"post-symbolic-regreesion-structure-regression",title:"Symbolic Regreesion? Structure Regression!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/structure-regression/"}},{id:"post-a-good-ml-theory-is-like-physics-a-physicist-39-s-analysis-of-grokking",title:"A Good ML Theory is Like Physics -- A Physicist&#39;s Analysis of Grokking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/physics-ml-theory/"}},{id:"project-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"project-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"project-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"project-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"project-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"project-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/talk_1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%6D%6C%69%75@%6D%69%74.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QeXHxlIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kindxiaoming","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/zimingliu11","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>