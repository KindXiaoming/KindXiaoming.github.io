<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> What's the difference -- (physics of) AI, physics, math and interpretability | Ziming Liu </title> <meta name="author" content="Ziming Liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kindxiaoming.github.io/blog/2026/ai-physics-interpretability/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>window.MathJax={tex:{tags:"ams"}};</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziming</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">media coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/talk/">talk </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">What's the difference -- (physics of) AI, physics, math and interpretability</h1> <p class="post-meta"> Created in January 05, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/physics-of-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Physics-of-AI</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In a previous <a href="/blog/2026/physics-of-ai-recipe/">blog post</a>, I discussed how to conduct <em>Physics of AI</em> research. Some friends later asked: <strong>Can AI and physics really be fully analogous?</strong> And <strong>what is the difference between Physics of AI and interpretability?</strong></p> <p>This article will discuss two points:</p> <ol> <li> <strong>AI and physics are not fully analogous</strong>, but that does not prevent us from borrowing methodologies from physics. In fact, <em>Physics of AI</em> is technically a <strong>simpler game than physics</strong>. Its main obstacles lie in <strong>publication culture</strong> (as discussed in a previous <a href="/blog/2026/physics-of-ai/">blog post</a>), not in the intrinsic difficulty of the subject.</li> <li> <strong>(As I define) Physics of AI is not the same as (what people usually define) interpretability</strong>. The key reason is that I see some genuinely new research perspectives that deserve a new name. What that name is does not really matter. If, in the future, the community expands the definition of interpretability, I would also be happy to simply call it interpretability.</li> </ol> <hr> <p>First, what’s the difference between physics and (physics of) AI?</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 80%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/ai-physics-interpretability/physics-vs-physics-of-ai-480.webp 480w,/assets/img/blogs/ai-physics-interpretability/physics-vs-physics-of-ai-800.webp 800w,/assets/img/blogs/ai-physics-interpretability/physics-vs-physics-of-ai-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/ai-physics-interpretability/physics-vs-physics-of-ai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h2 id="physics">Physics</h2> <p>If we count from the time of Newton, physics has taken about <strong>400 years</strong> to develop to its current state. Compared with the development of AI, this is extremely slow. This slowness comes from both <strong>practical constraints</strong> and <strong>philosophical constraints</strong>.</p> <p><strong>Practical constraints — physics research has strong directionality</strong></p> <ul> <li> <strong>Experiment-driven</strong>: theories emerge from experimental observations.</li> <li> <strong>“Human-centered” scales</strong>: starting from scales directly accessible to human perception, then extending in both directions—toward the microscopic (atoms, quarks) and the macroscopic (celestial bodies, the universe).</li> </ul> <p>Both directions are constrained by experimental and observational bottlenecks. It takes a long time to build microscopes and telescopes in the physical world.</p> <p><strong>Philosophical constraints</strong></p> <p>We do not actually know how the “creator” (physical laws) truly runs the universe. We can only infer laws from phenomena.<br> <em>All models are wrong, but some are useful.</em></p> <p>Even the most committed reductionists are troubled by two questions:</p> <ul> <li> <strong>Minimum and maximum scales</strong>: Are fundamental particles truly fundamental, e.g., can quarks or electrons be further divided? What lies beyond the universe?</li> <li> <strong>Cross-scale emergence</strong>: How do phenomena at different levels “emerge” from one another?</li> </ul> <hr> <h2 id="physics-of-ai">(Physics of) AI</h2> <p>For AI, <strong>none of the above constraints really exist</strong>.</p> <p><strong>No practical constraints</strong></p> <p>Apart from computational limits that prevent us from reaching arbitrarily large scales, we have <strong>no observational limitations</strong>. In principle, we can study the evolution of <strong>all weights and all neurons</strong>.</p> <p><strong>No philosophical constraints</strong></p> <p>We fully understand the “fundamental particles” of AI (neurons, weights, gradient descent), and we know the “boundary of the universe” (the entire neural network). <strong>We are the creator.</strong></p> <p>In principle, we can observe phenomena at any level at any time. There is no inherent directionality and no “human-centered” scale. AI systems are also <strong>closed systems</strong>—we know exactly how they evolve because we train them ourselves. Therefore, in principle, it must always be possible to explain large-scale phenomena using small-scale mechanisms, even if such explanations are not always useful.</p> <p>Physics is different: the continual discovery of “new physics” shows that its boundaries are still being broken.</p> <hr> <h2 id="mathematics">Mathematics</h2> <p>At this point, it is tempting to equate the physics of AI with mathematics, since both have clearly defined “fundamental particles”—called <strong>axioms</strong> in mathematics. But mathematics is clearly more difficult, for several reasons:</p> <ul> <li> <strong>Mathematics is also largely directional</strong>: starting from axioms and deriving results is a process from “microscopic” to “macroscopic.” In contrast, AI phenomenology can be studied simultaneously at multiple levels.</li> <li> <strong>Symbolic spaces make the definition of scales/levels and observations difficult</strong>: although backward reasoning (induction, abduction) exists in mathematics, it is often hard to define what “intermediate reasoning” even means, because symbolic spaces can be infinite. Neural networks (current AI systems), by contrast, have bounded topologies — no smaller than a neuron and no larger than the entire network.</li> <li> <strong>Cultural emphasis on rigor</strong>: mathematical rigor often comes at the cost of faithfulness to reality. AI research, in contrast, emphasizes practicality and is far less obsessed with rigor. Physics lies somewhere in between mathematics and AI in terms of rigor.</li> </ul> <hr> <h2 id="does-the-physics-of-ai-have-no-difficulties-then">Does the Physics of AI Have No Difficulties, Then?</h2> <p>Of course not.</p> <p>Philosophically, the physics of AI does not suffer from reductionism problems (we know the minimum and maximum scales, and cross-scale explanations are possible in principle). However, it may still face <strong>technical challenges</strong>. Even so, I remain optimistic. Two major technical questions are:</p> <ul> <li> <strong>How do we define levels and corresponding observations?</strong> Neurons, weights, and representations are clear, but how should we define circuits or modules? Once levels are defined, what observables should we introduce, and what phenomena should we observe? I gave partial answers in this <a href="/blog/2026/physics-of-ai-recipe/">blog post</a>.</li> <li> <strong>How do we characterize the connections (emergence) between levels?</strong> In principle, because AI systems are closed, lower-level phenomena should always be able to explain higher-level ones. In practice, however, finding explanations that are <em>simple</em> and <em>useful</em> is still a non-trivial problem. To be honest, I still have no clue how to answer this question. But more hands-on experiments will give the answer.</li> </ul> <hr> <h2 id="response-to-critiques-from-the-scaling-camp">Response to Critiques from the Scaling Camp</h2> <p>The issue of emergence is the main line of attack from the <strong>scaling camp</strong> against the <strong>research camp</strong>:<br> <em>How can phenomena observed in small models transfer to large models?</em></p> <p>Below is my response/attitude/belief:</p> <p><strong>Philosophical level</strong></p> <ul> <li>In natural science, analogies of emergence do not straightforwardly apply here (as discussed above). The ineffectiveness of reductionism in explaining emergence in nature (e.g., <a href="https://arxiv.org/abs/2503.01800" rel="external nofollow noopener" target="_blank">Hilbert’s sixth problem</a> is a hard problem) does not imply the same ineffectiveness in AI. Moreover, I personally do not like the word “emergence” since it seems to imply something mysterious (which might be appropriate for natural science, but not AI).</li> <li>Believe in <strong>shared explanations</strong>. Phenomenon A in small models and phenomenon B in large models may originate from the same cause. The absence of A in large models does not invalidate the value of studying it.</li> </ul> <p><strong>Methodological level</strong></p> <ul> <li> <strong>Be pragmatic</strong>. There are many concrete things we can do that have not yet been done. Only by doing them can we know whether they are useful.</li> <li>Be specific. Cross-scale phenomena usually fall into three categories: <ul> <li> <strong>Expansion</strong>: phenomenon A in small models becomes more pronounced in large models.</li> <li> <strong>Shrinkage</strong>: phenomenon A in small models becomes less visible in large models.</li> <li> <strong>Transformation</strong>: phenomenon A in small models turns into phenomenon B in large models.</li> </ul> <p>The scaling critique focuses on <em>shrinkage</em>. We are betting on <em>expansion</em> and <em>transformation</em>. Even if everything turns out to be shrinkage, our efforts are still not meaningless—at that point, I would more firmly side with the scaling camp.</p> </li> <li>We must acknowledge that academia cannot afford to train the largest models. We should call on large-model companies to open-source models—or at least open-source <em>phenomena</em>. Of course, academia must first identify interesting observables in toy and small models, so that industry knows <em>what</em> to observe.</li> </ul> <hr> <h2 id="interpretability">Interpretability</h2> <p>In a broad sense, interpretability includes everything—one could even say that <em>physics itself is about interpreting the universe</em>. In that sense, the physics of AI certainly belongs to interpretability.</p> <p>However, what people usually mean by interpretability refers narrowly to <strong>interpretability research in AI</strong>, and their understanding is constrained by past work:</p> <ul> <li>Some believe interpretability is just storytelling—pleasant but useless.</li> <li>Others believe interpretability is mathematics—rigorous but useless.</li> <li>The characterizations are often too coarse, making it unclear whether we are studying causality or correlation. This is precisely what <em>mechanistic interpretability</em> seeks to break away from.</li> <li>There is a lack of methodology: <em>at what level does an explanation count as complete?</em> </li> </ul> <p>Physics of AI differs from interpretability in all aspects:</p> <ul> <li>Starts with <strong>phenomenology</strong>, emphasizing faithful recording of phenomena and reducing the “storytelling” aspect (see previous <a href="/blog/2025/physics-of-ai/">blog post</a>).</li> <li>Is <strong>not mathematics</strong> (as discussed above). But we can adopt mathematical tools when they are useful.</li> <li>Characterizes phenomena at <strong>multiple levels</strong>, although I personally perfer startting from smallest “toy” models. You might have noticed that my recent technical blogs all study very simple models. The toy models already demonstrate very rich phenomena and I believe that the phenomena in toy models can transform (although maybe not directly transfer) to phenomena in larger models.</li> <li>Gradually builds a <strong>methodology</strong> to describe the connections between phenomena across levels.</li> </ul> <p>Therefore, we deserve a <strong>new name</strong> for what we are doing. <em>Physics of AI</em> is the name I chose.<br> Again, the name itself is not important. What matters is that it signals <strong>new territory and new treasures</strong>.</p> <hr> <h2 id="citation">Citation</h2> <p>If you find this article useful, please cite it as:</p> <p><strong>BibTeX:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2025physics-of-ai-recipe</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{What's the difference -- (physics of) AI, physics, math and interpretability}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liu, Ziming}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{January}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{https://KindXiaoming.github.io/blog/2026/ai-physics-interpretability/}</span>
<span class="p">}</span>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/physics-ml-theory/">A Good ML Theory is Like Physics -- A Physicist's Analysis of Grokking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/physics-of-ai/">Physics of AI Requires Mindset Shifts</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/structure-regression/">Symbolic Regreesion? Structure Regression!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/structuralism-ai/">Achieving AGI Intelligently – Structure, Not Scale</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/physics-of-ai-recipe/">Physics of AI – How to Begin</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ziming Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" crossorigin="anonymous"></script> <script>window.addEventListener("load",function(){console.log("Page loaded. MathJax available:",void 0!==window.MathJax),void 0!==window.MathJax?console.log("MathJax version:",window.MathJax.version):console.error("MathJax failed to load!")});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-media-coverage",title:"media coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/media/"}},{id:"nav-talk",title:"talk",description:"",section:"Navigation",handler:()=>{window.location.href="/talk/"}},{id:"post-sparse-attention-1-sticky-plateau-and-rank-collapse",title:"Sparse attention 1 -- sticky plateau and rank collapse",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-1/"}},{id:"post-unigram-toy-model-is-surprisingly-rich-representation-collapse-scaling-laws-learning-rate-schedule",title:"Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/unigram-toy-1/"}},{id:"post-fine-tuning-with-sparse-updates-a-toy-teacher-student-setup",title:"Fine-tuning with sparse updates? A toy teacher-student Setup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/fine-tuning-sparsity/"}},{id:"post-multi-head-cross-entropy-loss",title:"Multi-Head Cross Entropy Loss",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/multi-head-cross-entropy/"}},{id:"post-what-39-s-the-difference-physics-of-ai-physics-math-and-interpretability",title:"What&#39;s the difference -- (physics of) AI, physics, math and interpretability",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/ai-physics-interpretability/"}},{id:"post-representation-anisotropy-from-nonlinear-functions",title:"Representation anisotropy from nonlinear functions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/activation-anisotropy/"}},{id:"post-training-dynamics-of-a-single-relu-neuron",title:"Training dynamics of A Single ReLU Neuron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/single-relu-neuron/"}},{id:"post-physics-of-ai-how-to-begin",title:"Physics of AI \u2013 How to Begin",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-of-ai-recipe/"}},{id:"post-physics-of-feature-learning-1-a-perspective-from-nonlinearity",title:"Physics of Feature Learning 1 \u2013 A Perspective from Nonlinearity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/feature-learning-1/"}},{id:"post-physics-of-ai-requires-mindset-shifts",title:"Physics of AI Requires Mindset Shifts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/physics-of-ai/"}},{id:"post-achieving-agi-intelligently-structure-not-scale",title:"Achieving AGI Intelligently \u2013 Structure, Not Scale",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/structuralism-ai/"}},{id:"post-philosophical-thoughts-on-kolmogorov-arnold-networks",title:"Philosophical thoughts on Kolmogorov-Arnold Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kolmogorov-arnold-networks/"}},{id:"post-symbolic-regreesion-structure-regression",title:"Symbolic Regreesion? Structure Regression!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/structure-regression/"}},{id:"post-a-good-ml-theory-is-like-physics-a-physicist-39-s-analysis-of-grokking",title:"A Good ML Theory is Like Physics -- A Physicist&#39;s Analysis of Grokking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/physics-ml-theory/"}},{id:"project-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"project-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"project-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"project-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"project-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"project-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/talk_1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%6D%6C%69%75@%6D%69%74.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QeXHxlIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kindxiaoming","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/zimingliu11","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>