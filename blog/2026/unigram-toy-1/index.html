<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule | Ziming Liu </title> <meta name="author" content="Ziming Liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kindxiaoming.github.io/blog/2026/unigram-toy-1/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>window.MathJax={tex:{tags:"ams"}};</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziming</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">media coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/talk/">talk </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule</h1> <p class="post-meta"> Created in January 08, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/physics-of-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Physics-of-AI</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Author: Ziming Liu (刘子鸣)</strong></p> <hr> <h2 id="motivation">Motivation</h2> <p>Many phenomena have been observed during the training of LLMs—such as scaling laws and (early-stage) representation collapse. Empirically, there are also many training tricks—for example, carefully designing the learning rate schedule, including early LR warmup and late-stage LR decay. Are these phenomena and tricks <strong>specific to LLMs</strong>? Can we reproduce them in <strong>much simpler toy models</strong>?</p> <p>The goal of this blog post is to study an extremely simple <strong>Unigram model</strong>, and surprisingly, we find that many of the phenomena observed in LLMs already appear in this toy setting. Thanks to the simplicity of the toy model, we can more systematically investigate the <strong>origins</strong>, <strong>conditions</strong>, and <strong>control mechanisms</strong> of these phenomena.</p> <hr> <h2 id="problem-setup">Problem setup</h2> <p>We consider the case with context length equal to 1, i.e., predicting the next token \([B]\) from the current token \([A]\).</p> <p><strong>Dataset</strong><br> We consider a Unigram dataset—\([A]\) and \([B]\) are independent and are independently drawn from a discrete distribution. Let the vocabulary size be \(V\), and the discrete distribution be<br> \({\{p_i; \, p_i \ge 0, \sum_{i=1}^V p_i = 1\}}.\)</p> <p>Note that this dataset is even simpler than a Bigram dataset, because here the output \([B]\) does <strong>not</strong> depend on the input \([A]\) at all. The model’s task is simply to learn the token frequency distribution. One may ask: why study such a simple dataset, and does it have any relevance to natural language?</p> <ul> <li>First, the Zipf (heavy-tailed) frequency distribution is a characteristic feature of natural language. Although natural language has many other properties, here we focus exclusively on how <strong>single-token frequency distributions</strong> affect training dynamics.</li> <li>Second, in the learning rate warmup section below, we will provide evidence—namely a <em>sticky plateau</em>—suggesting that LLMs indeed exhibit signs of learning Unigram statistics during early training.</li> </ul> <p>For this dataset, the minimum achievable loss is simply the entropy of the frequency distribution: \(L_{\rm min} = S(\{p_i\}) = - \sum_{i=1}^V p_i \log p_i.\) We further assume that the frequencies follow a power law: \(p_i \sim i^{-\alpha}, \quad i = 1, 2, \dots, V,\) where \(\alpha\) controls the degree of heavy-tailedness. The case \(\alpha = 1\) corresponds to the standard Zipf distribution.</p> <p><strong>Model</strong><br> We consider a very simple model with only an embedding layer and an unembedding layer. For token \(i\), the embedding vector is \(E_i \in \mathbb{R}^D\) and the unembedding vector is \(U_i \in \mathbb{R}^D\). We usually tie the two weights, i.e., \(E_i = U_i.\)</p> <hr> <h2 id="1d-embedding-is-sufficient">1D embedding is sufficient</h2> <p>We take \(V = 10\), \(\alpha=1\), and embedding dimension \(D = 1\). Training uses batch size 128, while evaluation uses batch size 2,000,000. All data are drawn online. We find that training converges to the entropy (left and middle plots), and the learned embeddings show that tokens with higher frequency have larger values.</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 90%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/1d_embedding-480.webp 480w,/assets/img/blogs/unigram-toy-1/1d_embedding-800.webp 800w,/assets/img/blogs/unigram-toy-1/1d_embedding-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/1d_embedding-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/1d_embedding-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/1d_embedding.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Here is a small detail worth pointing out: if we <strong>do not tie</strong> \(U\) and \(E\), the model has more degrees of freedom and converges faster.</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 90%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/1d_embedding_untie-480.webp 480w,/assets/img/blogs/unigram-toy-1/1d_embedding_untie-800.webp 800w,/assets/img/blogs/unigram-toy-1/1d_embedding_untie-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/1d_embedding_untie-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/1d_embedding_untie-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/1d_embedding_untie.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>Mathematical construction</strong><br> Why emphasize this detail? When \(E\) and \(U\) are not tied, we can easily construct \(E_i = 1, \quad U_i = \log p_i,\) which exactly realizes the target distribution. However, when \(E\) and \(U\) share parameters, we require the logits \(E_i U\) and \(E_j U\) to induce the same probability distribution, which implies \(E_i = E_j\) and hence \(U_i = U_j\). This would lead to a uniform distribution, contradicting the heavy-tailed distribution we want.</p> <p>In practice, the model seems to find a sufficiently good trade-off: embeddings for different tokens have similar magnitudes, yet remain clearly distinguishable. Since NanoGPT uses weight tying, we will also continue to use weight tying in what follows.</p> <p>2026-01-13 update: if a layernorm layer is included after the embedding layer, even if embedding and unembedding layers are tied, the best perplexity/loss can be exactly achieved with embedding dimension = 1. This suggests that maybe we should directly provide (normalized) embeddings to the last layer, so that unigram can be easily learned.</p> <hr> <h2 id="representation-collapse">Representation collapse</h2> <p>Since a 1D embedding is already sufficient, an extreme case with higher-dimensional embeddings is that different embedding dimensions behave identically. In that case, the effective subspace dimension of the embeddings is actually 1. While reality may not be so extreme, this motivates us to measure the <strong>effective dimensionality</strong> of representations, which may be related to representation collapse observed in LLMs.</p> <p>For an embedding matrix, we perform principal component analysis (PCA), treat the explained variance ratios as a probability distribution, compute its entropy \(S\), and define the effective dimension as \(n_{\rm eff} = \exp(S).\)</p> <p>Taking \(V = 100\) and \(D = 100\), we indeed observe representation collapse, which becomes more pronounced for larger learning rates.</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 50%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/repr_collapse-480.webp 480w,/assets/img/blogs/unigram-toy-1/repr_collapse-800.webp 800w,/assets/img/blogs/unigram-toy-1/repr_collapse-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/repr_collapse-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/repr_collapse-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/repr_collapse.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h2 id="loss-scaling-laws">Loss scaling laws</h2> <p>We study temporal scaling of the form \(L - L_{\rm min} \propto t^{-\beta},\) where \(\beta\) measures the speed of loss decay. We vary \(\alpha\) and \(V\) and examine how \(\beta\) depends on them. We fix \(D = 100\) and learning rate \(\text{lr} = 0.001\).</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/scaling_law-480.webp 480w,/assets/img/blogs/unigram-toy-1/scaling_law-800.webp 800w,/assets/img/blogs/unigram-toy-1/scaling_law-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/scaling_law-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/scaling_law-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/scaling_law.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>We find that:</p> <ul> <li>larger \(V\) leads to smaller \(\beta\);</li> <li>larger \(\alpha\) leads to larger \(\beta\).</li> </ul> <p>Both trends are intuitive: larger \(V\) or smaller \(\alpha\) corresponds to a harder task.</p> <hr> <h2 id="learning-rate-decay">Learning rate decay</h2> <p>We next ask whether late-stage learning rate decay is helpful in this toy setup. We find that learning rate decay indeed helps, and the improvement becomes larger as the system size increases (i.e., larger embedding dimension \(D\)). We train for 2000 steps with \(\text{lr} = 0.01\), then linearly decay the learning rate from 0.01 to 0.001 over the final 1000 steps. We fix \(V = 100\) and \(\alpha = 1\).</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/lr_decay-480.webp 480w,/assets/img/blogs/unigram-toy-1/lr_decay-800.webp 800w,/assets/img/blogs/unigram-toy-1/lr_decay-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/lr_decay-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/lr_decay-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/lr_decay.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>How can we understand this? When the system has many degrees of freedom, and each update is normalized, many degrees of freedom may update in similar directions. Their combined effect can be too large, causing overshoot. In this case, reducing the learning rate is necessary to avoid overshooting.</p> <hr> <h2 id="learning-rate-warmup">Learning rate warmup</h2> <p>Can our experiments shed light on the necessity of learning rate warmup? In the representation collapse section, we showed that large learning rates lead to more severe representation collapse—this is one possible explanation.</p> <p>Here we provide another observation. In <em>Analyzing &amp; Reducing Learning Rate Warmup</em> (<a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/059445c2d5b3ef918079851628fef1d6-Paper-Conference.pdf" rel="external nofollow noopener" target="_blank">paper</a>), the authors found that without warmup, training descends faster initially but becomes slightly <em>sticky</em> around loss ≈ 7.5, after which it becomes slower than training with warmup:</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 30%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/unigram-toy-1/sticky_7d5-480.webp 480w,/assets/img/blogs/unigram-toy-1/sticky_7d5-800.webp 800w,/assets/img/blogs/unigram-toy-1/sticky_7d5-1400.webp 1400w,/assets/img/blogs/unigram-toy-1/sticky_7d5-1920.webp 1920w,/assets/img/blogs/unigram-toy-1/sticky_7d5-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/unigram-toy-1/sticky_7d5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>How should we interpret this value 7.5? Using our Unigram model, if we take \(V = 50304\) (NanoGPT) and \(\alpha = 1\) (Zipfian), we can compute the entropy to be 7.57. This may not be a coincidence.</p> <p>With a relatively large initial learning rate, the model may overly exploit Unigram token frequencies to reduce loss quickly, but because the steps are too large, it fails to capture more subtle structures in the data (Bigram, Trigram, or longer-range correlations). As a result, the model is attracted to a Unigram “saddle-point solution,” and escaping from it requires more time. Of course, this is only a hypothesis, and more complex toy models are needed to test it.</p> <p>Finally, from the perspective of neuron activations, there is another possible explanation: excessively large early learning rates may cause neurons to die more quickly. We discussed this possibility in a previous <a href="(/blog/2025/feature-learning-1/)">blog post</a>.</p> <hr> <h2 id="code">Code</h2> <p>Google Colab notebook available <a href="https://colab.research.google.com/drive/1aVARfgLyf13arPbXw2tODPWacCgWMhBi?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>.</p> <hr> <h2 id="citation">Citation</h2> <p>If you find this article useful, please cite it as:</p> <p><strong>BibTeX:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2026fine-unigram-toy-1</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liu, Ziming}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{January}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{https://KindXiaoming.github.io/blog/2026/unigram-toy-1/}</span>
<span class="p">}</span>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/induction-head-lr-schedule/">Emergence of Induction Head Depends on Learning Rate Schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/sparse-attention-4/">Sparse attention 4 -- previous token head</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/physics-ml-theory/">A Good ML Theory is Like Physics -- A Physicist's Analysis of Grokking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/sparse-attention-1/">Sparse attention 1 -- sticky plateau and rank collapse</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/single-relu-neuron/">Training dynamics of A Single ReLU Neuron</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ziming Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" crossorigin="anonymous"></script> <script>window.addEventListener("load",function(){console.log("Page loaded. MathJax available:",void 0!==window.MathJax),void 0!==window.MathJax?console.log("MathJax version:",window.MathJax.version):console.error("MathJax failed to load!")});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-media-coverage",title:"media coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/media/"}},{id:"nav-talk",title:"talk",description:"",section:"Navigation",handler:()=>{window.location.href="/talk/"}},{id:"post-when-i-say-quot-toy-models-quot-what-do-i-mean",title:"When I say &quot;toy models&quot;, what do I mean?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/toy/"}},{id:"post-on-the-physical-interpretation-of-drifting-generative-models",title:"On the physical interpretation of drifting generative models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-3/"}},{id:"post-physics-2-transformers-fail-to-maintain-physical-cosistency-for-circular-motion",title:"Physics 2 -- Transformers fail to maintain physical cosistency for circular motion",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-2/"}},{id:"post-physics-1-attention-can-39-t-exactly-simulate-uniform-linear-motion",title:"Physics 1 -- Attention can&#39;t exactly simulate uniform linear motion",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-1/"}},{id:"post-depth-4-flat-directions-in-weight-space-are-high-frequency-modes-in-function-space",title:"Depth 4 -- Flat directions (in weight space) are high frequency modes (in function space)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-4/"}},{id:"post-depth-3-fun-facts-about-loss-hessian-eigenvalues",title:"Depth 3 -- Fun facts about loss hessian eigenvalues",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-3/"}},{id:"post-diffusion-2-visualizing-flow-matching-temporal-dynamics",title:"Diffusion 2 -- Visualizing flow matching, temporal dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-2/"}},{id:"post-sparse-attention-7-stack-of-causal-attention-creates-implicit-positional-embedding-and-explaning-quot-loss-in-the-middle-quot",title:"Sparse attention 7 -- Stack of causal attention creates implicit positional embedding, and explaning &quot;Loss in the middle&quot;",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-7/"}},{id:"post-sparse-attention-6-in-context-associative-recall",title:"Sparse attention 6 -- In-context Associative recall",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-6/"}},{id:"post-mlp-2-effective-linearity-generalized-silu",title:"MLP 2 -- Effective linearity, Generalized SiLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-2/"}},{id:"post-mlp-1-gating-is-good-for-polynomials",title:"MLP 1 -- Gating is good for polynomials",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-1/"}},{id:"post-optimization-4-loss-spikes",title:"Optimization 4 -- Loss Spikes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-4/"}},{id:"post-optimization-3-depth-2-adding-bias-after-relu",title:"Optimization 3 / Depth 2 -- Adding Bias After ReLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-3/"}},{id:"post-optimization-2-elementwise-scale-reparametrization",title:"Optimization 2 -- Elementwise Scale Reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-2/"}},{id:"post-optimization-1-norm-reparametrization",title:"Optimization 1 -- Norm reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-1/"}},{id:"post-sparse-attention-5-attention-sink",title:"Sparse attention 5 -- Attention sink",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-5/"}},{id:"post-bigram-4-on-the-difficulty-of-spatial-map-emergence",title:"Bigram 4 -- On the difficulty of spatial map emergence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-4/"}},{id:"post-depth-1-understanding-pre-ln-and-post-ln",title:"Depth 1 -- Understanding Pre-LN and Post-LN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-1/"}},{id:"post-bigram-3-low-rank-structure",title:"Bigram 3 -- Low Rank Structure",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-3/"}},{id:"post-bigram-2-emergence-of-hyperbolic-spaces",title:"Bigram 2 -- Emergence of Hyperbolic Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-2/"}},{id:"post-bigram-1-walk-on-a-circle",title:"Bigram 1 -- Walk on a Circle",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-1/"}},{id:"post-diffusion-1-sparse-and-dense-neurons",title:"Diffusion 1 -- Sparse and Dense Neurons",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-1/"}},{id:"post-sparse-attention-4-previous-token-head",title:"Sparse attention 4 -- previous token head",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-4/"}},{id:"post-sparse-attention-3-inefficiency-of-extracting-similar-content",title:"Sparse attention 3 -- inefficiency of extracting similar content",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-3/"}},{id:"post-emergence-of-induction-head-depends-on-learning-rate-schedule",title:"Emergence of Induction Head Depends on Learning Rate Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/induction-head-lr-schedule/"}},{id:"post-sparse-attention-2-unattention-head-branching-dynamics",title:"Sparse attention 2 -- Unattention head, branching dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-2/"}},{id:"post-sparse-attention-1-sticky-plateau-and-rank-collapse",title:"Sparse attention 1 -- sticky plateau and rank collapse",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-1/"}},{id:"post-unigram-toy-model-is-surprisingly-rich-representation-collapse-scaling-laws-learning-rate-schedule",title:"Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/unigram-toy-1/"}},{id:"post-fine-tuning-with-sparse-updates-a-toy-teacher-student-setup",title:"Fine-tuning with sparse updates? A toy teacher-student Setup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/fine-tuning-sparsity/"}},{id:"post-multi-head-cross-entropy-loss",title:"Multi-Head Cross Entropy Loss",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/multi-head-cross-entropy/"}},{id:"post-what-39-s-the-difference-physics-of-ai-physics-math-and-interpretability",title:"What&#39;s the difference -- (physics of) AI, physics, math and interpretability",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/ai-physics-interpretability/"}},{id:"post-representation-anisotropy-from-nonlinear-functions",title:"Representation anisotropy from nonlinear functions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/activation-anisotropy/"}},{id:"post-training-dynamics-of-a-single-relu-neuron",title:"Training dynamics of A Single ReLU Neuron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/single-relu-neuron/"}},{id:"post-physics-of-ai-how-to-begin",title:"Physics of AI \u2013 How to Begin",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-of-ai-recipe/"}},{id:"post-physics-of-feature-learning-1-a-perspective-from-nonlinearity",title:"Physics of Feature Learning 1 \u2013 A Perspective from Nonlinearity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/feature-learning-1/"}},{id:"post-physics-of-ai-requires-mindset-shifts",title:"Physics of AI Requires Mindset Shifts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/physics-of-ai/"}},{id:"post-achieving-agi-intelligently-structure-not-scale",title:"Achieving AGI Intelligently \u2013 Structure, Not Scale",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/structuralism-ai/"}},{id:"post-philosophical-thoughts-on-kolmogorov-arnold-networks",title:"Philosophical thoughts on Kolmogorov-Arnold Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kolmogorov-arnold-networks/"}},{id:"post-symbolic-regreesion-structure-regression",title:"Symbolic Regreesion? Structure Regression!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/structure-regression/"}},{id:"post-a-good-ml-theory-is-like-physics-a-physicist-39-s-analysis-of-grokking",title:"A Good ML Theory is Like Physics -- A Physicist&#39;s Analysis of Grokking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/physics-ml-theory/"}},{id:"project-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"project-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"project-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"project-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"project-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"project-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/talk_1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%6D%6C%69%75@%6D%69%74.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QeXHxlIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kindxiaoming","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/zimingliu11","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>