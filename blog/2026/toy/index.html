<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> When I say "toy models", what do I mean? | Ziming Liu </title> <meta name="author" content="Ziming Liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kindxiaoming.github.io/blog/2026/toy/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>window.MathJax={tex:{tags:"ams"}};</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziming</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">media coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/talk/">talk </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">When I say "toy models", what do I mean?</h1> <p class="post-meta"> Created in February 07, 2026 </p> <p class="post-tags"> <a href="/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/tag/physics-of-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Physics-of-AI</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>Author: Ziming Liu (刘子鸣)</strong></p> <hr> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/methodology-toy/toy_teaser-480.webp 480w,/assets/img/blogs/methodology-toy/toy_teaser-800.webp 800w,/assets/img/blogs/methodology-toy/toy_teaser-1400.webp 1400w,/assets/img/blogs/methodology-toy/toy_teaser-1920.webp 1920w,/assets/img/blogs/methodology-toy/toy_teaser-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/methodology-toy/toy_teaser.png?ef7be79166415858a39dd99991395bcf" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="motivation">Motivation</h2> <p>When I talk with colleagues and students, they are often confused by what I call “toy models.” The confusion usually comes from two questions:<br> (1) What exactly is a toy model, and how does one come up with it?<br> (2) Toy models sound useless—what are they good for?</p> <p>The second question is essentially a special case of the first: only after you become familiar with a tool do you understand what it is useful for.</p> <p>The goal of this blog is therefore twofold: to clearly explain what a toy model is (for AI researchers), and to provide a <strong>methodology</strong>—how to <em>construct</em> toy models.</p> <hr> <h2 id="what-does-a-toy-model-mean-in-physics">What does a toy model mean in physics?</h2> <p>The term <em>toy model</em> comes from physics—at least, that is where I first encountered and grew fond of it during my physics training. It precisely captures a physicist’s research aesthetic: striking a delicate balance between <strong>simplicity</strong> and <strong>relevance</strong>.</p> <p>For example, magnetic materials exhibit a critical temperature (the Curie temperature): above it they are paramagnetic, below it ferromagnetic. To understand this phenomenon, Ernest Ising proposed the Ising model. The simplest Ising model, which only considers interactions between neighboring atoms, is already sufficient to produce this phase transition and even predict Curie temperatures for some materials.</p> <p>As another example, although animal shapes vary enormously, scientists have found that heat dissipation and energy consumption depend primarily on an animal’s <em>size</em>, not its detailed shape. For studying heat dissipation, a “spherical cow” (or “spherical chicken”) is therefore an excellent toy model.</p> <p>So what is the philosophy behind toy models in physics?</p> <blockquote> <p><strong>Einstein:</strong> <em>Everything should be made as simple as possible, but not simpler.</em></p> </blockquote> <blockquote> <p><strong>Max Tegmark</strong> (my PhD advisor):<br> <em>If we don’t understand something, we should resort to a simpler thing that we still don’t understand… until we get to something we can start to understand.</em></p> </blockquote> <p>You might argue that constructing toy models sounds like it requires genius. For instance, how did Ising come up with the Ising model? My argument is that building toy models requires at most <strong>10% talent</strong> and <strong>90% hard work</strong>—provided you have the <em>right methodology</em>. With the right methodology, anyone with 90% effort can outperform a “genius” relying on 10% talent alone. This is precisely the purpose of this article: to teach a methodology for constructing toy models.</p> <p>Before doing so, however, I must emphasize that toy models from physics cannot be transplanted wholesale into AI. We need to <strong>redefine</strong> what a toy model means in AI.</p> <hr> <h2 id="toy-model-in-ai-model--network--data">Toy model in AI? Model = Network + Data</h2> <p>In AI, <em>models</em> and <em>data</em> must be clearly distinguished.</p> <p>In physics, a toy model is just a <em>model</em> whose purpose is to explain <em>data</em>. Here, “data” refers to physical phenomena or laws, which are fixed in our universe and cannot be arbitrarily controlled.</p> <p>In AI, however, a “toy model” can refer either to the <strong>model (neural network)</strong> or to the <strong>data</strong>—and these two factors can be controlled independently. In particular, we have the superpower of <em>designing and manipulating data</em>, something that physics does not allow. To avoid ambiguity, when I specifically mean a neural network, I will use the word <em>Network</em> rather than <em>Model</em>. In short:</p> <blockquote> <p><strong>Model = Network + Data</strong></p> </blockquote> <p>This gives rise to four regimes: the network can be simple or complex, and the data can be simple or complex. The four regimes correspond to existing research paradigms:</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/methodology-toy/four_zone_today-480.webp 480w,/assets/img/blogs/methodology-toy/four_zone_today-800.webp 800w,/assets/img/blogs/methodology-toy/four_zone_today-1400.webp 1400w,/assets/img/blogs/methodology-toy/four_zone_today-1920.webp 1920w,/assets/img/blogs/methodology-toy/four_zone_today-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/methodology-toy/four_zone_today.png?611cf3887938056532ecae7ea3e23805" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <strong>Zone 1 — simple data, simple network.</strong><br> This is where much of ML theory lives. To prove theorems, both the data and the model must satisfy strong simplifying assumptions.</li> <li> <strong>Zone 2 — simple data, complex network.</strong><br> This is the regime of Zeyuan Zhu’s <em>Physics of LLMs</em>: carefully designed, controlled tasks paired with real-world LLMs.</li> <li> <strong>Zone 3 — complex data, simple network.</strong><br> This is the vibe of traditional science. Given complex observed data, scientists propose simple models that can generate it.</li> <li> <strong>Zone 4 — complex data, complex network.</strong><br> This is mainstream modern AI.</li> </ul> <p><strong>Definition of a Toy Model</strong><br> Anything outside Zone 4—i.e., Zones 1, 2, and 3—belongs to the realm of <em>toy models</em>. Which toy model one should study depends entirely on one’s goal. Here are a few concrete examples:</p> <ul> <li> <strong>Zone 1:</strong> I want to study the emergence of sparse attention and gain as much quantitative, possibly analytic, understanding as possible. Both the network and the data should be as simple as possible.<br> See: <a href="https://arxiv.org/pdf/2505.17863" rel="external nofollow noopener" target="_blank">“The emergence of sparse attention: impact of data distribution and benefits of repetition”</a>.</li> <li> <strong>Zone 2:</strong> I want to decompose LLM capabilities by studying their behavior on simpler, more controllable tasks.<br> See Zeyuan Zhu’s <a href="https://physics.allen-zhu.com/" rel="external nofollow noopener" target="_blank">Physics of LLM</a>.</li> <li> <strong>Zone 3:</strong> I want to test whether data possesses a certain structure. For example, if an equivariant network fits the data well, the data likely has that symmetry; if not, it probably doesn’t. This closely resembles hypothesis testing in traditional science.<br> See: <a href="https://arxiv.org/abs/2109.13901" rel="external nofollow noopener" target="_blank">Physics-augmented learning</a>, <a href="https://arxiv.org/abs/1905.11481" rel="external nofollow noopener" target="_blank">AI Feynman</a>.</li> </ul> <hr> <h2 id="an-important-mindset-interpolation">An important mindset: interpolation</h2> <p>A common criticism of toy models is:</p> <blockquote> <p>What works in a toy model may not work in a real model—and even if it does, it may work for entirely different reasons.</p> </blockquote> <p>At its core, this criticism argues that toy models and real models feel completely disconnected, making transfer nontrivial.</p> <p><strong>The solution: interpolation.</strong><br> We should find a <em>path</em> connecting toy models and real models—akin to the notion of <em>homotopy</em> in mathematics.</p> <h3 id="why-interpolate">Why interpolate?</h3> <p><strong>Knowledge is created at the boundary between the known and the unknown.</strong> If we fully understand a toy model and the real model behaves differently, there must be a phase change (sharp or smooth) along the path connecting them. Understanding the phase change is key to understanding the difference between the toy setup and the real setup. Starting from the toy model (known) and gradually moving toward the real model (unknown) mirrors how humans learn. Fully known is trivial; fully unknown is confusing. The sweet spot—half-known, half-unknown—is where information gain is maximized. Research is, at its core, an information-gathering game.</p> <h3 id="how-to-interpolate">How to interpolate?</h3> <ul> <li> <strong>Directionality:</strong> move from simple to complex, or from complex to simple.</li> <li> <strong>Locality:</strong> change one feature at a time; avoid overly large jumps.</li> </ul> <p>Here are a few (abstracted) examples from projects I’ve supervised:</p> <ul> <li>A complex model shows strange behavior on real data (Zone 4). We hypothesize similar behavior might appear on simpler data. A student constructs a simple dataset (Zone 2), but the behavior differs. After failing to “complexify” the simple data to match reality, we realize the real data itself has a tunable parameter that can simplify it.<br> <strong>Lesson:</strong> not only can you make simple data more complex—you can also make complex data simpler.</li> <li>A diffusion model exhibits an intriguing phenomenon on CIFAR-10 (Zone 4). A student builds a toy setup (Zone 1): simple 2D data and a simple MLP. The phenomenon appears, but it’s unclear whether the mechanisms match. The toy metric doesn’t transfer. I then emphasize interpolation: network and data complexity can be adjusted independently. For example, keep a complex network (U-Net or DiT) but simplify the data to one prototype image per CIFAR class—only ten images total. This yields complex networks with simple data (Zone 2).<br> <strong>Lesson:</strong> maintain an interpolation mindset. Simplicity vs. complexity is not binary—it is continuous and multidimensional.</li> </ul> <hr> <h2 id="the-map-of-my-physics-of-ai">The map of my “physics of AI”</h2> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/methodology-toy/four_zone_physics_of_ai-480.webp 480w,/assets/img/blogs/methodology-toy/four_zone_physics_of_ai-800.webp 800w,/assets/img/blogs/methodology-toy/four_zone_physics_of_ai-1400.webp 1400w,/assets/img/blogs/methodology-toy/four_zone_physics_of_ai-1920.webp 1920w,/assets/img/blogs/methodology-toy/four_zone_physics_of_ai-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/methodology-toy/four_zone_physics_of_ai.png?4bc46a63a6b02dc90cd64c2a100b0b84" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Finally, how does the Zone 1–4 framework guide my <em>Physics of AI</em> program?</p> <p>The ultimate goal is, of course, Zone 4. But I argue that we should start from foundations in Zone 1—while distinguishing this effort from ML theory. ML theory is theory-driven, prioritizing rigor and carefully “feeling the elephant’s trunk.” Physics of AI is experiment- and phenomenon-driven, prioritizing intuition and breadth—touching many sides of the elephant and assembling a coherent picture.</p> <p>I view Physics of AI as progressing through three stages:</p> <ul> <li> <strong>Stage 1:</strong> Study training dynamics on simple data and simple models. This may sound trivial, but it isn’t—there is a rich landscape of dynamics and many failure modes, some of which appear connected to failures in LLMs. The goal is to catalog phenomena (e.g., grokking). In physics terms: <em>what are the behaviors of the fundamental particles?</em> In AI, the “particles” (attention, MLPs, etc.) are already given; we only need to characterize them.</li> <li> <strong>Stage 2:</strong> Study training dynamics on simple data but complex models. This is actually almost trivial once Stage 1 is done: we combine well-understood modules and add corrections to capture their interactions. At this stage, we begin to build systematic recipes for architectures and optimizers. Physics analogy: <em>what are the interactions between particles?</em> </li> <li> <strong>Stage 3:</strong> The hardest step—moving from Stage 2 to Stage 3—requires understanding the data itself and therefore draws on domain expertise across fields. Physics analogy: <em>what is the Standard Model of AI?</em> </li> </ul> <hr> <h2 id="citation">Citation</h2> <p>If you find this article useful, please cite it as:</p> <p><strong>BibTeX:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2026methodology-toy</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{When I say "toy models", what do I mean?}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liu, Ziming}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{February}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{https://KindXiaoming.github.io/blog/2026/toy/}</span>
<span class="p">}</span>
</code></pre></div></div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/physics-ml-theory/">A Good ML Theory is Like Physics -- A Physicist's Analysis of Grokking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/ai-physics-interpretability/">What's the difference -- (physics of) AI, physics, math and interpretability</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/physics-of-ai-recipe/">Physics of AI – How to Begin</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/unigram-toy-1/">Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/structure-regression/">Symbolic Regreesion? Structure Regression!</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ziming Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" crossorigin="anonymous"></script> <script>window.addEventListener("load",function(){console.log("Page loaded. MathJax available:",void 0!==window.MathJax),void 0!==window.MathJax?console.log("MathJax version:",window.MathJax.version):console.error("MathJax failed to load!")});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-media-coverage",title:"media coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/media/"}},{id:"nav-talk",title:"talk",description:"",section:"Navigation",handler:()=>{window.location.href="/talk/"}},{id:"post-when-i-say-quot-toy-models-quot-what-do-i-mean",title:"When I say &quot;toy models&quot;, what do I mean?",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/toy/"}},{id:"post-on-the-physical-interpretation-of-drifting-generative-models",title:"On the physical interpretation of drifting generative models",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-3/"}},{id:"post-physics-2-transformers-fail-to-maintain-physical-cosistency-for-circular-motion",title:"Physics 2 -- Transformers fail to maintain physical cosistency for circular motion",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-2/"}},{id:"post-physics-1-attention-can-39-t-exactly-simulate-uniform-linear-motion",title:"Physics 1 -- Attention can&#39;t exactly simulate uniform linear motion",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-1/"}},{id:"post-depth-4-flat-directions-in-weight-space-are-high-frequency-modes-in-function-space",title:"Depth 4 -- Flat directions (in weight space) are high frequency modes (in function space)",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-4/"}},{id:"post-depth-3-fun-facts-about-loss-hessian-eigenvalues",title:"Depth 3 -- Fun facts about loss hessian eigenvalues",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-3/"}},{id:"post-diffusion-2-visualizing-flow-matching-temporal-dynamics",title:"Diffusion 2 -- Visualizing flow matching, temporal dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-2/"}},{id:"post-sparse-attention-7-stack-of-causal-attention-creates-implicit-positional-embedding-and-explaning-quot-loss-in-the-middle-quot",title:"Sparse attention 7 -- Stack of causal attention creates implicit positional embedding, and explaning &quot;Loss in the middle&quot;",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-7/"}},{id:"post-sparse-attention-6-in-context-associative-recall",title:"Sparse attention 6 -- In-context Associative recall",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-6/"}},{id:"post-mlp-2-effective-linearity-generalized-silu",title:"MLP 2 -- Effective linearity, Generalized SiLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-2/"}},{id:"post-mlp-1-gating-is-good-for-polynomials",title:"MLP 1 -- Gating is good for polynomials",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-1/"}},{id:"post-optimization-4-loss-spikes",title:"Optimization 4 -- Loss Spikes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-4/"}},{id:"post-optimization-3-depth-2-adding-bias-after-relu",title:"Optimization 3 / Depth 2 -- Adding Bias After ReLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-3/"}},{id:"post-optimization-2-elementwise-scale-reparametrization",title:"Optimization 2 -- Elementwise Scale Reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-2/"}},{id:"post-optimization-1-norm-reparametrization",title:"Optimization 1 -- Norm reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-1/"}},{id:"post-sparse-attention-5-attention-sink",title:"Sparse attention 5 -- Attention sink",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-5/"}},{id:"post-bigram-4-on-the-difficulty-of-spatial-map-emergence",title:"Bigram 4 -- On the difficulty of spatial map emergence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-4/"}},{id:"post-depth-1-understanding-pre-ln-and-post-ln",title:"Depth 1 -- Understanding Pre-LN and Post-LN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-1/"}},{id:"post-bigram-3-low-rank-structure",title:"Bigram 3 -- Low Rank Structure",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-3/"}},{id:"post-bigram-2-emergence-of-hyperbolic-spaces",title:"Bigram 2 -- Emergence of Hyperbolic Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-2/"}},{id:"post-bigram-1-walk-on-a-circle",title:"Bigram 1 -- Walk on a Circle",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-1/"}},{id:"post-diffusion-1-sparse-and-dense-neurons",title:"Diffusion 1 -- Sparse and Dense Neurons",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-1/"}},{id:"post-sparse-attention-4-previous-token-head",title:"Sparse attention 4 -- previous token head",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-4/"}},{id:"post-sparse-attention-3-inefficiency-of-extracting-similar-content",title:"Sparse attention 3 -- inefficiency of extracting similar content",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-3/"}},{id:"post-emergence-of-induction-head-depends-on-learning-rate-schedule",title:"Emergence of Induction Head Depends on Learning Rate Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/induction-head-lr-schedule/"}},{id:"post-sparse-attention-2-unattention-head-branching-dynamics",title:"Sparse attention 2 -- Unattention head, branching dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-2/"}},{id:"post-sparse-attention-1-sticky-plateau-and-rank-collapse",title:"Sparse attention 1 -- sticky plateau and rank collapse",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-1/"}},{id:"post-unigram-toy-model-is-surprisingly-rich-representation-collapse-scaling-laws-learning-rate-schedule",title:"Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/unigram-toy-1/"}},{id:"post-fine-tuning-with-sparse-updates-a-toy-teacher-student-setup",title:"Fine-tuning with sparse updates? A toy teacher-student Setup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/fine-tuning-sparsity/"}},{id:"post-multi-head-cross-entropy-loss",title:"Multi-Head Cross Entropy Loss",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/multi-head-cross-entropy/"}},{id:"post-what-39-s-the-difference-physics-of-ai-physics-math-and-interpretability",title:"What&#39;s the difference -- (physics of) AI, physics, math and interpretability",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/ai-physics-interpretability/"}},{id:"post-representation-anisotropy-from-nonlinear-functions",title:"Representation anisotropy from nonlinear functions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/activation-anisotropy/"}},{id:"post-training-dynamics-of-a-single-relu-neuron",title:"Training dynamics of A Single ReLU Neuron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/single-relu-neuron/"}},{id:"post-physics-of-ai-how-to-begin",title:"Physics of AI \u2013 How to Begin",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-of-ai-recipe/"}},{id:"post-physics-of-feature-learning-1-a-perspective-from-nonlinearity",title:"Physics of Feature Learning 1 \u2013 A Perspective from Nonlinearity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/feature-learning-1/"}},{id:"post-physics-of-ai-requires-mindset-shifts",title:"Physics of AI Requires Mindset Shifts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/physics-of-ai/"}},{id:"post-achieving-agi-intelligently-structure-not-scale",title:"Achieving AGI Intelligently \u2013 Structure, Not Scale",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/structuralism-ai/"}},{id:"post-philosophical-thoughts-on-kolmogorov-arnold-networks",title:"Philosophical thoughts on Kolmogorov-Arnold Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kolmogorov-arnold-networks/"}},{id:"post-symbolic-regreesion-structure-regression",title:"Symbolic Regreesion? Structure Regression!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/structure-regression/"}},{id:"post-a-good-ml-theory-is-like-physics-a-physicist-39-s-analysis-of-grokking",title:"A Good ML Theory is Like Physics -- A Physicist&#39;s Analysis of Grokking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/physics-ml-theory/"}},{id:"project-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"project-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"project-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"project-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"project-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"project-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/talk_1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%6D%6C%69%75@%6D%69%74.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QeXHxlIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kindxiaoming","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/zimingliu11","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>