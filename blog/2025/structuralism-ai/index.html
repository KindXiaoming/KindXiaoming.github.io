<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Achieving AGI Intelligently – Structure, Not Scale | Ziming Liu </title> <meta name="author" content="Ziming Liu"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kindxiaoming.github.io/blog/2025/structuralism-ai/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script>window.MathJax={tex:{tags:"ams"}};</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ziming</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/media/">media coverage </a> </li> <li class="nav-item "> <a class="nav-link" href="/talk/">talk </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Achieving AGI Intelligently – Structure, Not Scale</h1> <p class="post-meta"> Created in December 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/structuralism-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Structuralism-AI</a>   <a href="/blog/tag/agi"> <i class="fa-solid fa-hashtag fa-sm"></i> AGI</a>     ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><strong>TL;DR</strong>: Structuralism AI is the inevitable path beyond scaling — <em>not because scaling is wrong, but because it will eventually hit the energy/data wall.</em></p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 70%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/structuralist-ai-480.webp 480w,/assets/img/blogs/structuralist-ai-800.webp 800w,/assets/img/blogs/structuralist-ai-1400.webp 1400w,/assets/img/blogs/structuralist-ai-1920.webp 1920w,/assets/img/blogs/structuralist-ai-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/structuralist-ai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <p>Scaling laws have been the most important guiding principle in AI over the past few years. That much is undeniable. They have driven unprecedented performance gains and largely unified both industry and academia around a single direction. Yet the logic behind scaling laws is surprisingly simple: because AI struggles with Out-of-Distribution (OOD) tasks, the most straightforward solution is to collect more data and train larger models, until everything becomes In-distribution.</p> <p>Scaling laws therefore offer a future that is <strong>robust, but inefficient</strong>.</p> <p>Let me be very clear about my position. If we completely ignore constraints on energy and data, I do not doubt that <strong>pure scaling alone can eventually reach AGI</strong>. I have never doubted this. If compute were infinite and data unlimited, large models could, in principle, cover everything. The problem is precisely that the real world is not like this.</p> <p>So the question becomes:<br> is there a <strong>more intelligent way</strong> to achieve AGI?</p> <p>I believe there is.<br> And the answer is not more scale, but <strong>more structure</strong>.</p> <p>It is important that I deliberately use the word <em>structure</em>, not <em>symbol</em>. This distinction is intentional, and I will explain it later.</p> <hr> <p>Why do we need structure? Because structure enables <strong>compression</strong>. And compression lies at the core of intelligence. As Ilya once put it: <em>Compression is intelligence.</em></p> <p>Consider a simple example. If fractal structure is allowed, the intrinsic complexity of a snowflake is extremely low—it is highly compressible. If structure is disallowed and one must describe it point by point, the apparent complexity of a snowflake is effectively infinite. Today’s scaling laws resemble the latter approach: using ever more parameters and computation to fit massive apparent complexity.</p> <p>A deeper example comes from celestial mechanics. The most direct way to model planetary motion is to store the positions of planets at every moment in time—a lookup table with enormous cost. Kepler achieved the first true compression by realizing that planetary orbits are ellipses, a global structure in time that dramatically reduced complexity. Newton achieved the second compression by discovering local dynamical laws that explained even more with fewer parameters.</p> <p>And where does modern AI stand? Work by Vafa and collaborators shows that Transformers do not naturally learn Newtonian world models. This means that <strong>correct physical structure does not reliably emerge from scale alone</strong>.</p> <p>Our current expectation that “structure will eventually emerge” often resembles primitive humans praying to gods. The only difference is that our sacrifices—data and compute—actually work (to some extent). And precisely because they work, we lack sufficient motivation to search for a more scientific, more intelligent path forward.</p> <hr> <p>Structure is explicit and everywhere in the natural sciences. In fact, without structure, there would be no natural science at all.</p> <p>If we draw an analogy with the Tycho–Kepler–Newton trajectory, today’s AI still largely lives in the Tycho era: experiment-driven, data-driven, with only the beginnings of a Keplerian phase—empirical laws such as scaling laws. But unlike the history of celestial mechanics, we have turned these empirical laws into articles of faith, aggressively scaling experiments and engineering systems around them, rather than treating them as clues toward a deeper theory—a “Newtonian mechanics of AI.”</p> <p>From an intellectual perspective, this is not progress. It is regression.</p> <hr> <p>At this point, you might say: “This is just another piece criticizing scaling and foundation models.”<br> It is not.</p> <p>My stance is clear and neutral. According to the No Free Lunch theorem, every model has its domain of applicability and its limitations. Or, more bluntly: <em>All models are wrong, but some are useful.</em></p> <p>The real issue is not whether to use foundation models, but whether we understand that <strong>different tasks possess fundamentally different structures and compressibility</strong>. From a compression perspective, and by analogy with the natural sciences, tasks fall naturally into categories. Some are <strong>“physics-like”</strong>: highly compressible, with symbolic formulas emerging from continuous data. Some are <strong>“chemistry-like”</strong>: substantially compressible, with clear structure but incomplete or approximate symbols. Others are <strong>“biology-like”</strong>: only weakly compressible, dominated by empirical regularities and statistical induction. Pure noise exists as well, but no model can handle it, so we can safely ignore it.</p> <p>An ideal intelligent system should be able to recognize which kind of task it is facing and apply the appropriate degree of compression.</p> <p>Symbolic models excel at physics-like tasks but fail on chemistry- and biology-like ones. Connectionist models, due to their generality, can in principle handle all types—but precisely because they lack structure, they are extremely inefficient on physics- and chemistry-like problems.</p> <table class="table table-bordered"> <thead> <tr> <th style="border-right: 2px solid #dee2e6;"> <div style="display: flex; justify-content: space-between;"> </div> </th> <th>"Physics-like" tasks</th> <th>"Chemistry-like" tasks</th> <th>"Biology-like" tasks</th> </tr> </thead> <tbody> <tr> <td>**Symbolism AI**</td> <td>Excellent</td> <td>Poor</td> <td>Poor</td> </tr> <tr> <td>**Connectionism AI**</td> <td>Inefficient</td> <td>Inefficient</td> <td>Good</td> </tr> <tr> <td>**Structuralism AI**</td> <td>Good</td> <td>Good</td> <td>Good</td> </tr> </tbody> </table> <hr> <p>This is why I argue for <strong>Structuralism</strong>.</p> <p>Symbolism starts from physics-like tasks. Connectionism starts from biology-like tasks. A natural question follows: can we build AI starting from chemistry-like tasks? Structuralism, by design, aims to capture this intermediate regime. We want symbols—stricter, more discrete structures—to emerge from structure, and we want empirical regularities—looser structures—to be learned by relaxing structure from data.</p> <p>In supervised learning, this distinction is already quite concrete. Linear regression is symbolic. Multi-layer perceptrons are connectionist. EQL represents a neural–symbolic hybrid. Kolmogorov–Arnold Networks (KANs), by contrast, are structuralist. The representation theory underlying KANs compactly captures the compositional structure of multivariate functions. As a result, KANs are neither structureless like MLPs, nor overconstrained like linear models, nor plagued by instability from neural–symbolic mismatch.</p> <p>Structuralism is not a compromise. It is a unification.</p> <div class="row mt-3"> <div class="mt-3 mt-md-0" style="width: 100%; margin: 0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blogs/four-ai-philosophy-480.webp 480w,/assets/img/blogs/four-ai-philosophy-800.webp 800w,/assets/img/blogs/four-ai-philosophy-1400.webp 1400w,/assets/img/blogs/four-ai-philosophy-1920.webp 1920w,/assets/img/blogs/four-ai-philosophy-2560.webp 2560w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/blogs/four-ai-philosophy.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <p>But the real world goes far beyond supervised learning. We do not merely learn structure from data—we compare structures, reuse structures, and build “structures of structures” (category theory!). This is <strong>abstraction</strong>.</p> <p>I want to argue explicitly: <strong>abstraction is one of the central bottlenecks to AGI</strong>. This aligns closely with Rich Sutton’s emphasis on abstraction in OaK architecture. Continual learning is fundamentally about preserving abstract invariances across tasks. Adaptivity and fluidity—for example in ARC-AGI—is about in-context abstraction. And many ARC-AGI tasks are, at their core, simplified forms of intuitive physics, an essential element of world models.</p> <p>So how do we enable abstraction? I will be honest: I do not yet have a complete solution.</p> <p>One insight is that abstraction arises from comparing and reusing structures. Attention is also a mechanism for comparison, but it implicitly assumes that structure can be embedded into vector spaces and that similarity can be measured by dot products. In reality, most structures are not isomorphic to vector spaces. We do this largely because it fits GPU computation, not because it is cognitively or scientifically correct.</p> <hr> <p>I believe current AI development is <strong>secretly structuralist</strong>, but mostly in an extrinsic sense. Reasoning is structured. Agent frameworks are structured. Yet the underlying models remain connectionist. This is extrinsic structuralism, and it relies heavily on Chain-of-Thought-like data to explicitly supervise structure.</p> <p>I am willing to bet that the next wave of progress will come from <strong>intrinsic structuralism</strong>: injecting general-purpose structure into models, or enabling structure to emerge internally, without relying on explicit CoT supervision.</p> <p>From an application perspective, the AGI we actually need must be efficient, adaptive, generalizable, and physically grounded. Structure is essential to all four. The physical world itself is highly structured and highly compressible—compositionality, sparsity, temporal locality. Without these structures appearing in our models, world models will remain out of reach.</p> <hr> <p><strong>In summary, Structuralism AI represents a path fundamentally different from scaling. It may be harder, but it is also more interesting, richer in opportunity, and far more promising in the long run.</strong></p> <p><strong>In 2026, it’s time to bet/work on something different.</strong></p> <hr> <h2 id="citation">Citation</h2> <p>If you find this article useful, please cite it as:</p> <p><strong>BibTeX:</strong></p> <div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2025structuralism-ai</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{Achieving AGI Intelligently -- Structure, Not Scale}</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Liu, Ziming}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span><span class="p">=</span><span class="s">{December}</span><span class="p">,</span>
  <span class="na">url</span><span class="p">=</span><span class="s">{https://KindXiaoming.github.io/blog/2025/structuralism-ai/}</span>
<span class="p">}</span>
</code></pre></div></div> <p><strong>Text citation:</strong></p> <p>Liu, Ziming (December 2025). Achieving AGI Intelligently – Structure, Not Scale. KindXiaoming.github.io. https://KindXiaoming.github.io/blog/2025/structuralism-ai/</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/physics-ml-theory/">A Good ML Theory is Like Physics -- A Physicist's Analysis of Grokking</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/structure-regression/">Symbolic Regreesion? Structure Regression!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/ai-physics-interpretability/">What's the difference -- (physics of) AI, physics, math and interpretability</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2026/unigram-toy-1/">Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/physics-of-ai/">Physics of AI Requires Mindset Shifts</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Ziming Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" crossorigin="anonymous"></script> <script>window.addEventListener("load",function(){console.log("Page loaded. MathJax available:",void 0!==window.MathJax),void 0!==window.MathJax?console.log("MathJax version:",window.MathJax.version):console.error("MathJax failed to load!")});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-media-coverage",title:"media coverage",description:"",section:"Navigation",handler:()=>{window.location.href="/media/"}},{id:"nav-talk",title:"talk",description:"",section:"Navigation",handler:()=>{window.location.href="/talk/"}},{id:"post-sparse-attention-6-in-context-associative-recall",title:"Sparse attention 6 -- In-context Associative recall",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-6/"}},{id:"post-mlp-2-effective-linearity-generalized-silu",title:"MLP 2 -- Effective linearity, Generalized SiLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-2/"}},{id:"post-mlp-1-gating-is-good-for-polynomials",title:"MLP 1 -- Gating is good for polynomials",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/mlp-1/"}},{id:"post-optimization-4-loss-spikes",title:"Optimization 4 -- Loss Spikes",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-4/"}},{id:"post-optimization-3-depth-2-adding-bias-after-relu",title:"Optimization 3 / Depth 2 -- Adding Bias After ReLU",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-3/"}},{id:"post-optimization-2-elementwise-scale-reparametrization",title:"Optimization 2 -- Elementwise Scale Reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-2/"}},{id:"post-optimization-1-norm-reparametrization",title:"Optimization 1 -- Norm reparametrization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/optimization-1/"}},{id:"post-sparse-attention-5-attention-sink",title:"Sparse attention 5 -- Attention sink",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-5/"}},{id:"post-bigram-4-on-the-difficulty-of-spatial-map-emergence",title:"Bigram 4 -- On the difficulty of spatial map emergence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-4/"}},{id:"post-depth-1-understanding-pre-ln-and-post-ln",title:"Depth 1 -- Understanding Pre-LN and Post-LN",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/depth-1/"}},{id:"post-bigram-3-low-rank-structure",title:"Bigram 3 -- Low Rank Structure",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-3/"}},{id:"post-bigram-2-emergence-of-hyperbolic-spaces",title:"Bigram 2 -- Emergence of Hyperbolic Spaces",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-2/"}},{id:"post-bigram-1-walk-on-a-circle",title:"Bigram 1 -- Walk on a Circle",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/bigram-1/"}},{id:"post-diffusion-1-sparse-and-dense-neurons",title:"Diffusion 1 -- Sparse and Dense Neurons",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/diffusion-1/"}},{id:"post-sparse-attention-4-previous-token-head",title:"Sparse attention 4 -- previous token head",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-4/"}},{id:"post-sparse-attention-3-inefficiency-of-extracting-similar-content",title:"Sparse attention 3 -- inefficiency of extracting similar content",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-3/"}},{id:"post-emergence-of-induction-head-depends-on-learning-rate-schedule",title:"Emergence of Induction Head Depends on Learning Rate Schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/induction-head-lr-schedule/"}},{id:"post-sparse-attention-2-unattention-head-branching-dynamics",title:"Sparse attention 2 -- Unattention head, branching dynamics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-2/"}},{id:"post-sparse-attention-1-sticky-plateau-and-rank-collapse",title:"Sparse attention 1 -- sticky plateau and rank collapse",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/sparse-attention-1/"}},{id:"post-unigram-toy-model-is-surprisingly-rich-representation-collapse-scaling-laws-learning-rate-schedule",title:"Unigram toy model is surprisingly rich -- representation collapse, scaling laws, learning rate schedule",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/unigram-toy-1/"}},{id:"post-fine-tuning-with-sparse-updates-a-toy-teacher-student-setup",title:"Fine-tuning with sparse updates? A toy teacher-student Setup",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/fine-tuning-sparsity/"}},{id:"post-multi-head-cross-entropy-loss",title:"Multi-Head Cross Entropy Loss",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/multi-head-cross-entropy/"}},{id:"post-what-39-s-the-difference-physics-of-ai-physics-math-and-interpretability",title:"What&#39;s the difference -- (physics of) AI, physics, math and interpretability",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/ai-physics-interpretability/"}},{id:"post-representation-anisotropy-from-nonlinear-functions",title:"Representation anisotropy from nonlinear functions",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/activation-anisotropy/"}},{id:"post-training-dynamics-of-a-single-relu-neuron",title:"Training dynamics of A Single ReLU Neuron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/single-relu-neuron/"}},{id:"post-physics-of-ai-how-to-begin",title:"Physics of AI \u2013 How to Begin",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/physics-of-ai-recipe/"}},{id:"post-physics-of-feature-learning-1-a-perspective-from-nonlinearity",title:"Physics of Feature Learning 1 \u2013 A Perspective from Nonlinearity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2026/feature-learning-1/"}},{id:"post-physics-of-ai-requires-mindset-shifts",title:"Physics of AI Requires Mindset Shifts",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/physics-of-ai/"}},{id:"post-achieving-agi-intelligently-structure-not-scale",title:"Achieving AGI Intelligently \u2013 Structure, Not Scale",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/structuralism-ai/"}},{id:"post-philosophical-thoughts-on-kolmogorov-arnold-networks",title:"Philosophical thoughts on Kolmogorov-Arnold Networks",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kolmogorov-arnold-networks/"}},{id:"post-symbolic-regreesion-structure-regression",title:"Symbolic Regreesion? Structure Regression!",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/structure-regression/"}},{id:"post-a-good-ml-theory-is-like-physics-a-physicist-39-s-analysis-of-grokking",title:"A Good ML Theory is Like Physics -- A Physicist&#39;s Analysis of Grokking",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/physics-ml-theory/"}},{id:"project-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"project-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"project-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"project-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"project-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"project-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/talk_1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%6D%6C%69%75@%6D%69%74.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=QeXHxlIAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kindxiaoming","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/zimingliu11","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>